{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b3de0a",
   "metadata": {},
   "source": [
    "# UNSW2018 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9a34bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a01586b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data = './UNSW2018/4image_final' \n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=data, transform=transform)\n",
    "loader = DataLoader(dataset=dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ffbd280e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extractor (consistent with the definition during training)\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.noise = nn.Parameter(torch.randn(84))  # Feature confusion\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = nn.ReLU()(self.fc1(out))\n",
    "        out = self.fc2(out) + self.noise  # Bottleneck layer and feature confusion\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cacb5a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the weights of the trained feature extractor\n",
    "model_dir = './CIC/model'  \n",
    "feature_extractor = FeatureExtractor().to(device)\n",
    "feature_extractor.load_state_dict(torch.load(os.path.join(model_dir, 'feature_extractor_CIC.pth'), map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5379a8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature extraction and saving\n",
    "def extract_and_save_features(feature_extractor, loader, device):\n",
    "    feature_extractor.eval()\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            features = feature_extractor(images)\n",
    "            features_list.append(features.cpu().numpy())\n",
    "            labels_list.extend(labels.cpu().numpy())\n",
    "    \n",
    "    features_array = np.concatenate(features_list, axis=0)\n",
    "    labels_array = np.array(labels_list)\n",
    "\n",
    "    np.save('./CIC/features/features_UNSW2018.npy', features_array)\n",
    "    np.save('./CIC/features/labels_UNSW2018.npy', labels_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d478abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs('./CIC/features', exist_ok=True)\n",
    "extract_and_save_features(feature_extractor, loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ceb34e",
   "metadata": {},
   "source": [
    "# Identification_UNSW2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72d436ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "import time\n",
    "import gc\n",
    "import psutil\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, cohen_kappa_score\n",
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "013a7cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49c55e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from features.npy and labels.npy files\n",
    "features = np.load('./CIC/features/features_UNSW2018.npy')\n",
    "labels = np.load('./CIC/features/labels_UNSW2018.npy')\n",
    "\n",
    "features = torch.tensor(features, dtype=torch.float32).to(device)\n",
    "labels = torch.tensor(labels, dtype=torch.long).to(device)\n",
    "\n",
    "input_dim = features.shape[1]\n",
    "num_classes = len(np.unique(labels.cpu().numpy()))\n",
    "\n",
    "classifiers = [\n",
    "    (\"SimpleNN\", SimpleNN(input_dim=input_dim, num_classes=num_classes).to(device))\n",
    "]\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56a95d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SimpleNN 10 fold cross validation results:\n",
      "Average accuracy: 99.27%\n",
      "Average precision: 99.29%\n",
      "Average Recall: 99.27%\n",
      "Average F1: 0.99\n",
      "Average Kappa: 0.99\n",
      "Average train time: 30.99 S\n",
      "Average test time: 0.003 S\n",
      "Average memory: 30.53 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for name, classifier in classifiers:\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "    kappas = []\n",
    "    conf_matrix_sum = np.zeros((num_classes, num_classes))\n",
    "    training_times = []\n",
    "    testing_times = []\n",
    "    memory_usages = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(features):\n",
    "        X_train, X_test = features[train_index], features[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        train_dataset = TensorDataset(X_train, y_train)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "        classifier.apply(lambda m: m.reset_parameters() if hasattr(m, 'reset_parameters') else None)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(classifier.parameters(), lr=0.001)\n",
    "        \n",
    "        # Record memory usage before training\n",
    "        gc.collect()\n",
    "        process = psutil.Process(os.getpid())\n",
    "        start_memory = process.memory_info().rss / (1024 * 1024) \n",
    "        start_train_time = time.time()\n",
    "        classifier.train()\n",
    "        num_epochs = 10\n",
    "        for epoch in range(num_epochs):\n",
    "            for inputs, targets in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = classifier(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        end_train_time = time.time()\n",
    "        \n",
    "        classifier.eval()\n",
    "        with torch.no_grad():\n",
    "            start_test_time = time.time()\n",
    "            outputs = classifier(X_test)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            end_test_time = time.time()\n",
    "        \n",
    "        accuracy = accuracy_score(y_test.cpu().numpy(), preds.cpu().numpy())\n",
    "        precision = precision_score(y_test.cpu().numpy(), preds.cpu().numpy(), average='weighted')\n",
    "        recall = recall_score(y_test.cpu().numpy(), preds.cpu().numpy(), average='weighted')\n",
    "        f1 = f1_score(y_test.cpu().numpy(), preds.cpu().numpy(), average='weighted')\n",
    "        kappa = cohen_kappa_score(y_test.cpu().numpy(), preds.cpu().numpy())\n",
    "        conf_matrix = confusion_matrix(y_test.cpu().numpy(), preds.cpu().numpy(), labels=range(num_classes))\n",
    "        \n",
    "        accuracies.append(accuracy)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1s.append(f1)\n",
    "        kappas.append(kappa)\n",
    "        conf_matrix_sum += conf_matrix \n",
    "        training_times.append(end_train_time - start_train_time)\n",
    "        testing_times.append(end_test_time - start_test_time)\n",
    "        \n",
    "        # Record memory usage after training and calculate the difference\n",
    "        end_memory = process.memory_info().rss / (1024 * 1024)  \n",
    "        memory_usages.append(end_memory - start_memory)\n",
    "    \n",
    "    print(f'\\n{name} 10 fold cross validation results:')\n",
    "    print(f'Average accuracy: {np.mean(accuracies) * 100:.2f}%')\n",
    "    print(f'Average precision: {np.mean(precisions) * 100:.2f}%')\n",
    "    print(f'Average Recall: {np.mean(recalls) * 100:.2f}%')\n",
    "    print(f'Average F1: {np.mean(f1s):.2f}')\n",
    "    print(f'Average Kappa: {np.mean(kappas):.2f}')\n",
    "    print(f'Average train time: {np.mean(training_times):.2f} S')\n",
    "    print(f'Average test time: {np.mean(testing_times):.3f} S')\n",
    "    print(f'Average memory: {np.mean(memory_usages):.2f} MB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bd8f0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d702e0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e375c6e1",
   "metadata": {},
   "source": [
    "# UNSW2019 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d1d4240",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data = './UNSW2019/4image_final' \n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=data, transform=transform)\n",
    "loader = DataLoader(dataset=dataset, batch_size=64, shuffle=False)\n",
    "# Feature extractor (consistent with the definition during training)\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.noise = nn.Parameter(torch.randn(84))  # Feature confusion\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = nn.ReLU()(self.fc1(out))\n",
    "        out = self.fc2(out) + self.noise  # Bottleneck layer and feature confusion\n",
    "        return out\n",
    "# Load the weights of the trained feature extractor\n",
    "model_dir = './CIC/model'  \n",
    "feature_extractor = FeatureExtractor().to(device)\n",
    "feature_extractor.load_state_dict(torch.load(os.path.join(model_dir, 'feature_extractor_CIC.pth'), map_location=device))\n",
    "# Feature extraction and saving\n",
    "def extract_and_save_features(feature_extractor, loader, device):\n",
    "    feature_extractor.eval()\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            features = feature_extractor(images)\n",
    "            features_list.append(features.cpu().numpy())\n",
    "            labels_list.extend(labels.cpu().numpy())\n",
    "    \n",
    "    features_array = np.concatenate(features_list, axis=0)\n",
    "    labels_array = np.array(labels_list)\n",
    "\n",
    "    np.save('./CIC/features/features_UNSW2019.npy', features_array)\n",
    "    np.save('./CIC/features/labels_UNSW2019.npy', labels_array)\n",
    "os.makedirs('./CIC/features', exist_ok=True)\n",
    "extract_and_save_features(feature_extractor, loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29c07149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SimpleNN 10 fold cross validation results:\n",
      "Average accuracy: 99.95%\n",
      "Average precision: 99.94%\n",
      "Average Recall: 99.95%\n",
      "Average F1: 1.00\n",
      "Average Kappa: 1.00\n",
      "Average train time: 105.10 S\n",
      "Average test time: 0.019 S\n",
      "Average memory: 89.24 MB\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "# Load data from features.npy and labels.npy files\n",
    "features = np.load('./CIC/features/features_UNSW2019.npy')\n",
    "labels = np.load('./CIC/features/labels_UNSW2019.npy')\n",
    "\n",
    "features = torch.tensor(features, dtype=torch.float32).to(device)\n",
    "labels = torch.tensor(labels, dtype=torch.long).to(device)\n",
    "\n",
    "input_dim = features.shape[1]\n",
    "num_classes = len(np.unique(labels.cpu().numpy()))\n",
    "\n",
    "classifiers = [\n",
    "    (\"SimpleNN\", SimpleNN(input_dim=input_dim, num_classes=num_classes).to(device))\n",
    "]\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "for name, classifier in classifiers:\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "    kappas = []\n",
    "    conf_matrix_sum = np.zeros((num_classes, num_classes))\n",
    "    training_times = []\n",
    "    testing_times = []\n",
    "    memory_usages = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(features):\n",
    "        X_train, X_test = features[train_index], features[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        train_dataset = TensorDataset(X_train, y_train)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "        classifier.apply(lambda m: m.reset_parameters() if hasattr(m, 'reset_parameters') else None)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(classifier.parameters(), lr=0.001)\n",
    "        \n",
    "        # Record memory usage before training\n",
    "        gc.collect()\n",
    "        process = psutil.Process(os.getpid())\n",
    "        start_memory = process.memory_info().rss / (1024 * 1024) \n",
    "        start_train_time = time.time()\n",
    "        classifier.train()\n",
    "        num_epochs = 10\n",
    "        for epoch in range(num_epochs):\n",
    "            for inputs, targets in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = classifier(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        end_train_time = time.time()\n",
    "        \n",
    "        classifier.eval()\n",
    "        with torch.no_grad():\n",
    "            start_test_time = time.time()\n",
    "            outputs = classifier(X_test)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            end_test_time = time.time()\n",
    "        \n",
    "        accuracy = accuracy_score(y_test.cpu().numpy(), preds.cpu().numpy())\n",
    "        precision = precision_score(y_test.cpu().numpy(), preds.cpu().numpy(), average='weighted')\n",
    "        recall = recall_score(y_test.cpu().numpy(), preds.cpu().numpy(), average='weighted')\n",
    "        f1 = f1_score(y_test.cpu().numpy(), preds.cpu().numpy(), average='weighted')\n",
    "        kappa = cohen_kappa_score(y_test.cpu().numpy(), preds.cpu().numpy())\n",
    "        conf_matrix = confusion_matrix(y_test.cpu().numpy(), preds.cpu().numpy(), labels=range(num_classes))\n",
    "        \n",
    "        accuracies.append(accuracy)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1s.append(f1)\n",
    "        kappas.append(kappa)\n",
    "        conf_matrix_sum += conf_matrix \n",
    "        training_times.append(end_train_time - start_train_time)\n",
    "        testing_times.append(end_test_time - start_test_time)\n",
    "        \n",
    "        # Record memory usage after training and calculate the difference\n",
    "        end_memory = process.memory_info().rss / (1024 * 1024)  \n",
    "        memory_usages.append(end_memory - start_memory)\n",
    "    \n",
    "    print(f'\\n{name} 10 fold cross validation results:')\n",
    "    print(f'Average accuracy: {np.mean(accuracies) * 100:.2f}%')\n",
    "    print(f'Average precision: {np.mean(precisions) * 100:.2f}%')\n",
    "    print(f'Average Recall: {np.mean(recalls) * 100:.2f}%')\n",
    "    print(f'Average F1: {np.mean(f1s):.2f}')\n",
    "    print(f'Average Kappa: {np.mean(kappas):.2f}')\n",
    "    print(f'Average train time: {np.mean(training_times):.2f} S')\n",
    "    print(f'Average test time: {np.mean(testing_times):.3f} S')\n",
    "    print(f'Average memory: {np.mean(memory_usages):.2f} MB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf3c65de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f2643e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b3180fb",
   "metadata": {},
   "source": [
    "# IMC dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "13a2c859",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data = './IMC/4image_final' \n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.Resize((28, 28)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=data, transform=transform)\n",
    "loader = DataLoader(dataset=dataset, batch_size=64, shuffle=False)\n",
    "# Feature extractor (consistent with the definition during training)\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.noise = nn.Parameter(torch.randn(84))  # Feature confusion\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = nn.ReLU()(self.fc1(out))\n",
    "        out = self.fc2(out) + self.noise  # Bottleneck layer and feature confusion\n",
    "        return out\n",
    "# Load the weights of the trained feature extractor\n",
    "model_dir = './CIC/model'  \n",
    "feature_extractor = FeatureExtractor().to(device)\n",
    "feature_extractor.load_state_dict(torch.load(os.path.join(model_dir, 'feature_extractor_CIC.pth'), map_location=device))\n",
    "# Feature extraction and saving\n",
    "def extract_and_save_features(feature_extractor, loader, device):\n",
    "    feature_extractor.eval()\n",
    "    features_list = []\n",
    "    labels_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            features = feature_extractor(images)\n",
    "            features_list.append(features.cpu().numpy())\n",
    "            labels_list.extend(labels.cpu().numpy())\n",
    "    \n",
    "    features_array = np.concatenate(features_list, axis=0)\n",
    "    labels_array = np.array(labels_list)\n",
    "\n",
    "    np.save('./CIC/features/features_IMC.npy', features_array)\n",
    "    np.save('./CIC/features/labels_IMC.npy', labels_array)\n",
    "os.makedirs('./CIC/features', exist_ok=True)\n",
    "extract_and_save_features(feature_extractor, loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33235fe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SimpleNN 10 fold cross validation results:\n",
      "Average accuracy: 96.72%\n",
      "Average precision: 96.68%\n",
      "Average Recall: 96.72%\n",
      "Average F1: 0.96\n",
      "Average Kappa: 0.96\n",
      "Average train time: 6.30 S\n",
      "Average test time: 0.005 S\n",
      "Average memory: 4.21 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = nn.ReLU()(self.fc1(x))\n",
    "        x = nn.ReLU()(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "# Load data from features.npy and labels.npy files\n",
    "features = np.load('./CIC/features/features_IMC.npy')\n",
    "labels = np.load('./CIC/features/labels_IMC.npy')\n",
    "\n",
    "features = torch.tensor(features, dtype=torch.float32).to(device)\n",
    "labels = torch.tensor(labels, dtype=torch.long).to(device)\n",
    "\n",
    "input_dim = features.shape[1]\n",
    "num_classes = len(np.unique(labels.cpu().numpy()))\n",
    "\n",
    "classifiers = [\n",
    "    (\"SimpleNN\", SimpleNN(input_dim=input_dim, num_classes=num_classes).to(device))\n",
    "]\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "for name, classifier in classifiers:\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1s = []\n",
    "    kappas = []\n",
    "    conf_matrix_sum = np.zeros((num_classes, num_classes))\n",
    "    training_times = []\n",
    "    testing_times = []\n",
    "    memory_usages = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(features):\n",
    "        X_train, X_test = features[train_index], features[test_index]\n",
    "        y_train, y_test = labels[train_index], labels[test_index]\n",
    "        train_dataset = TensorDataset(X_train, y_train)\n",
    "        train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "        classifier.apply(lambda m: m.reset_parameters() if hasattr(m, 'reset_parameters') else None)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(classifier.parameters(), lr=0.001)\n",
    "        \n",
    "        # Record memory usage before training\n",
    "        gc.collect()\n",
    "        process = psutil.Process(os.getpid())\n",
    "        start_memory = process.memory_info().rss / (1024 * 1024) \n",
    "        start_train_time = time.time()\n",
    "        classifier.train()\n",
    "        num_epochs = 10\n",
    "        for epoch in range(num_epochs):\n",
    "            for inputs, targets in train_loader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = classifier(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        end_train_time = time.time()\n",
    "        \n",
    "        classifier.eval()\n",
    "        with torch.no_grad():\n",
    "            start_test_time = time.time()\n",
    "            outputs = classifier(X_test)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            end_test_time = time.time()\n",
    "        \n",
    "        accuracy = accuracy_score(y_test.cpu().numpy(), preds.cpu().numpy())\n",
    "        precision = precision_score(y_test.cpu().numpy(), preds.cpu().numpy(), average='weighted')\n",
    "        recall = recall_score(y_test.cpu().numpy(), preds.cpu().numpy(), average='weighted')\n",
    "        f1 = f1_score(y_test.cpu().numpy(), preds.cpu().numpy(), average='weighted')\n",
    "        kappa = cohen_kappa_score(y_test.cpu().numpy(), preds.cpu().numpy())\n",
    "        conf_matrix = confusion_matrix(y_test.cpu().numpy(), preds.cpu().numpy(), labels=range(num_classes))\n",
    "        \n",
    "        accuracies.append(accuracy)\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "        f1s.append(f1)\n",
    "        kappas.append(kappa)\n",
    "        conf_matrix_sum += conf_matrix \n",
    "        training_times.append(end_train_time - start_train_time)\n",
    "        testing_times.append(end_test_time - start_test_time)\n",
    "        \n",
    "        # Record memory usage after training and calculate the difference\n",
    "        end_memory = process.memory_info().rss / (1024 * 1024)  \n",
    "        memory_usages.append(end_memory - start_memory)\n",
    "    \n",
    "    print(f'\\n{name} 10 fold cross validation results:')\n",
    "    print(f'Average accuracy: {np.mean(accuracies) * 100:.2f}%')\n",
    "    print(f'Average precision: {np.mean(precisions) * 100:.2f}%')\n",
    "    print(f'Average Recall: {np.mean(recalls) * 100:.2f}%')\n",
    "    print(f'Average F1: {np.mean(f1s):.2f}')\n",
    "    print(f'Average Kappa: {np.mean(kappas):.2f}')\n",
    "    print(f'Average train time: {np.mean(training_times):.2f} S')\n",
    "    print(f'Average test time: {np.mean(testing_times):.3f} S')\n",
    "    print(f'Average memory: {np.mean(memory_usages):.2f} MB')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea825973",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f332e25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aced6089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
